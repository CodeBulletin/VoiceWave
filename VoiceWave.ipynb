{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Mount"
      ],
      "metadata": {
        "id": "iGpTKF3945nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHmBWyJX45Va",
        "outputId": "789b96b3-8aa4-4dec-ec50-e0618477449e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# installing and creating directory"
      ],
      "metadata": {
        "id": "PzNGmUfPZ5UL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/SpeechDatasets  # one time only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S03lyBu6J5VD",
        "outputId": "35e9ad87-4074-4245-a3cb-c75940152ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/SpeechDatasets’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/drive/MyDrive/SpeechDatasets  # if something goes wrong"
      ],
      "metadata": {
        "id": "1AF4GCZ_JoyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8h6mbC1N3Jtl",
        "outputId": "6ebcd92b-98ae-49a7-e761-6465cfc64f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mltu\n",
            "  Downloading mltu-1.0.15-py3-none-any.whl (36 kB)\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf2onnx\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from mltu) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mltu) (4.65.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mltu) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mltu) (1.22.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mltu) (4.7.0.72)\n",
            "Collecting Pillow>=9.4.0 (from mltu)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.15.0 (from mltu)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: librosa>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mltu) (0.10.0.post2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mltu) (3.7.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Collecting flatbuffers<3.0,>=1.12 (from tf2onnx)\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (0.3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.9.2->mltu) (1.0.5)\n",
            "Collecting coloredlogs (from onnxruntime>=1.15.0->mltu)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.15.0->mltu) (1.11.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mltu) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mltu) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.9.2->mltu) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.9.2->mltu) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa>=0.9.2->mltu) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.9.2->mltu) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.9.2->mltu) (1.15.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.15.0->mltu)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.15.0->mltu) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.9.2->mltu) (2.21)\n",
            "Installing collected packages: flatbuffers, Pillow, onnx, humanfriendly, tf2onnx, coloredlogs, onnxruntime, mltu\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "Successfully installed Pillow-10.0.0 coloredlogs-15.0.1 flatbuffers-2.0.7 humanfriendly-10.0 mltu-1.0.15 onnx-1.14.0 onnxruntime-1.15.1 tf2onnx-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install mltu onnx tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"CRNN-01\""
      ],
      "metadata": {
        "id": "mlJfojfeXVW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "QEyKsTs73zIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import typing\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "\n",
        "from mltu.tensorflow.model_utils import activation_layer\n",
        "from mltu.utils.text_utils import ctc_decoder\n",
        "from mltu.inferenceModel import OnnxInferenceModel\n",
        "from mltu.configs import BaseModelConfigs\n",
        "from mltu.preprocessors import WavReader\n",
        "from mltu.tensorflow.dataProvider import DataProvider\n",
        "from mltu.transformers import LabelIndexer, LabelPadding, SpectrogramPadding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from mltu.tensorflow.losses import CTCloss\n",
        "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
        "from mltu.tensorflow.metrics import CERMetric, WERMetric"
      ],
      "metadata": {
        "id": "gKKg2CQ_3yKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Datasets"
      ],
      "metadata": {
        "id": "tx84BH8dKGBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LJdataset_download_path = \"/content/drive/MyDrive/SpeechDatasets\"\n",
        "def download_and_unzip_LJ(url, extract_to):\n",
        "    dataset_path = os.path.join(extract_to, \"LJSpeech-1.1.tar.bz2\")\n",
        "    if not (os.path.isfile(dataset_path) and os.path.exists(dataset_path)):\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            total_length = int(r.headers.get(\"Content-Length\"))\n",
        "            with tqdm(total=total_length, unit='iB', unit_scale=True, desc=\"Downloading\") as bar:\n",
        "                with open(dataset_path, \"wb\") as fout:\n",
        "                    for data in r.iter_content(1024 * 1024):\n",
        "                        if data:\n",
        "                            bar.update(len(data))\n",
        "                            fout.write(data)\n",
        "\n",
        "    total_members = 13104\n",
        "\n",
        "    # Create a progress bar using tqdm\n",
        "    with tarfile.open(dataset_path, \"r:bz2\") as tar:\n",
        "        progress = tqdm(total=total_members, unit=\"file\", desc=\"Extracting\")\n",
        "\n",
        "        # Extract each file while updating the progress bar\n",
        "        while True:\n",
        "            member = tar.next()\n",
        "            if member is None:\n",
        "                break\n",
        "\n",
        "            tar.extract(member, path=extract_to)\n",
        "            progress.update()\n",
        "\n",
        "LJdataset_path = os.path.join(LJdataset_download_path, \"LJSpeech-1.1\")\n",
        "LJmetadata_path = LJdataset_path + \"/metadata.csv\"\n",
        "LJwavs_path = LJdataset_path + \"/wavs/\"\n",
        "\n",
        "if not os.path.exists(LJdataset_path):\n",
        "    download_and_unzip_LJ(\"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\", extract_to=LJdataset_download_path)\n"
      ],
      "metadata": {
        "id": "0Xe1OA3G3nBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configs"
      ],
      "metadata": {
        "id": "_u3VN0Cp5ypn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelConfigs(BaseModelConfigs):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model_path = os.path.join(f\"/content/drive/MyDrive/{model_name}\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
        "        self.frame_length = 256\n",
        "        self.frame_step = 160\n",
        "        self.fft_length = 384\n",
        "\n",
        "        self.vocab = \"abcdefghijklmnopqrstuvwxyz'?! \"\n",
        "        self.input_shape = None\n",
        "        self.max_text_length = None\n",
        "        self.max_spectrogram_length = None\n",
        "\n",
        "        self.batch_size = 8\n",
        "        self.learning_rate = 0.0005\n",
        "        self.train_epochs = 10\n",
        "        self.train_workers = 20"
      ],
      "metadata": {
        "id": "Hia5cE1h5yX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Provider"
      ],
      "metadata": {
        "id": "mJphKgdG6Dpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ModelConfigs object to store model configurations\n",
        "configs = ModelConfigs()"
      ],
      "metadata": {
        "id": "mCC05TRHNjh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read metadata file and parse it\n",
        "metadata_df = pd.read_csv(LJmetadata_path, sep=\"|\", header=None, quoting=3)\n",
        "metadata_df.columns = [\"file_name\", \"transcription\", \"normalized_transcription\"]\n",
        "metadata_df = metadata_df[[\"file_name\", \"normalized_transcription\"]]\n",
        "\n",
        "# structure the dataset where each row is a list of [wav_file_path, sound transcription]\n",
        "dataset = [[f\"{LJwavs_path}/{file}.wav\", label.lower()] for file, label in metadata_df.values.tolist()]"
      ],
      "metadata": {
        "id": "E-r9oyLmZtz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_text_length, max_spectrogram_length = 0, 0\n",
        "for file_path, label in tqdm(dataset):\n",
        "    spectrogram = WavReader.get_spectrogram(file_path, frame_length=configs.frame_length, frame_step=configs.frame_step, fft_length=configs.fft_length)\n",
        "    valid_label = [c for c in label if c in configs.vocab]\n",
        "    max_text_length = max(max_text_length, len(valid_label))\n",
        "    max_spectrogram_length = max(max_spectrogram_length, spectrogram.shape[0])\n",
        "    configs.input_shape = [max_spectrogram_length, spectrogram.shape[1]]\n",
        "\n",
        "configs.max_spectrogram_length = max_spectrogram_length\n",
        "configs.max_text_length = max_text_length\n",
        "\n",
        "# Do not run this unless the dataset changes or gets some additions"
      ],
      "metadata": {
        "id": "bBT_ZKnO39q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9f2f5f-b20f-48af-d906-b7bba8dffa13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13100/13100 [1:46:28<00:00,  2.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configs.save()"
      ],
      "metadata": {
        "id": "2o7EI49xNgpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = \"\"\"\n",
        "batch_size: 8\n",
        "fft_length: 384\n",
        "frame_length: 256\n",
        "frame_step: 160\n",
        "input_shape:\n",
        "- 1392\n",
        "- 193\n",
        "learning_rate: 0.0005\n",
        "max_spectrogram_length: 1392\n",
        "max_text_length: 186\n",
        "train_epochs: 3\n",
        "train_workers: 20\n",
        "vocab: 'abcdefghijklmnopqrstuvwxyz''?! '\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CRNN-01/202306191330/configs.yaml\", \"w\") as file:\n",
        "    file.write(config)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/CRNN-01/202306191330/configs.yaml\", \"r\") as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9drOBVcE3FG",
        "outputId": "05303151-1dbc-4ad5-b2a8-14ddc190bc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "batch_size: 8\n",
            "fft_length: 384\n",
            "frame_length: 256\n",
            "frame_step: 160\n",
            "input_shape:\n",
            "- 1392\n",
            "- 193\n",
            "learning_rate: 0.0005\n",
            "max_spectrogram_length: 1392\n",
            "max_text_length: 186\n",
            "train_epochs: 3\n",
            "train_workers: 20\n",
            "vocab: 'abcdefghijklmnopqrstuvwxyz''?! '\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the config\n",
        "\n",
        "configs = BaseModelConfigs.load(\"/content/drive/MyDrive/CRNN-01/202306191330/configs.yaml\")\n",
        "\n",
        "# Create a data provider for the dataset\n",
        "data_provider = DataProvider(\n",
        "    dataset=dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[\n",
        "        WavReader(frame_length=configs.frame_length, frame_step=configs.frame_step, fft_length=configs.fft_length),\n",
        "    ],\n",
        "    transformers=[\n",
        "        SpectrogramPadding(max_spectrogram_length=configs.max_spectrogram_length, padding_value=0),\n",
        "        LabelIndexer(configs.vocab),\n",
        "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab)),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data_provider, val_data_provider = data_provider.split(split = 0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7qTqd5Ocrkv",
        "outputId": "a651af35-f4ab-40ec-f49d-bf2ac8a90445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:DataProvider:Skipping Dataset validation...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "NHtxI_l3Xktx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crnn_model_01(input_dim, output_dim, activation=\"leaky_relu\", dropout=0.2):\n",
        "\n",
        "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
        "\n",
        "    # expand dims to add channel dimension\n",
        "    input = layers.Lambda(lambda x: tf.expand_dims(x, axis=-1))(inputs)\n",
        "\n",
        "    # Convolution layer 1\n",
        "    x = layers.Conv2D(filters=32, kernel_size=[11, 41], strides=[2, 2], padding=\"same\", use_bias=False)(input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = activation_layer(x, activation=\"leaky_relu\")\n",
        "\n",
        "    # Convolution layer 2\n",
        "    x = layers.Conv2D(filters=32, kernel_size=[11, 21], strides=[1, 2], padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = activation_layer(x, activation=\"leaky_relu\")\n",
        "\n",
        "    # Reshape the resulted volume to feed the RNNs layers\n",
        "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
        "\n",
        "    # RNN layers\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
        "\n",
        "    # Dense layer\n",
        "    x = layers.Dense(256)(x)\n",
        "    x = activation_layer(x, activation=\"leaky_relu\")\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    # Classification layer\n",
        "    output = layers.Dense(output_dim + 1, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "PqjTlVw4XmsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WavToTextModel(OnnxInferenceModel):\n",
        "    def __init__(self, char_list: typing.Union[str, list], *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.char_list = char_list\n",
        "\n",
        "    def predict(self, data: np.ndarray):\n",
        "        data_pred = np.expand_dims(data, axis=0)\n",
        "\n",
        "        preds = self.model.run(None, {self.input_name: data_pred})[0]\n",
        "\n",
        "        text = ctc_decoder(preds, self.char_list)[0]\n",
        "\n",
        "        return text"
      ],
      "metadata": {
        "id": "3HlmDzJ6Yfcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "gTWLVIY_6HTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configs.model_path = \"/content/drive/MyDrive/CRNN-01/202306191330\""
      ],
      "metadata": {
        "id": "0yCfemJKd5N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(configs.input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ol11G6F3Lbj",
        "outputId": "705b5c28-36a0-4f9e-e45e-c40639e243a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1392, 193]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = crnn_model_01(\n",
        "    input_dim = configs.input_shape,\n",
        "    output_dim = len(configs.vocab),\n",
        "    dropout=0.2\n",
        ")\n",
        "\n",
        "# Compile the model and print summary\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate),\n",
        "    loss=CTCloss(),\n",
        "    metrics=[\n",
        "        CERMetric(vocabulary=configs.vocab),\n",
        "        WERMetric(vocabulary=configs.vocab)\n",
        "    ],\n",
        "    run_eagerly=False\n",
        ")\n",
        "model.summary(line_length=110)\n",
        "\n",
        "model.load_weights(configs.model_path + \"/model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bkjohksUaxw",
        "outputId": "670f0eae-9065-4d89-fd89-f934253ae38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "______________________________________________________________________________________________________________\n",
            " Layer (type)                                    Output Shape                                Param #          \n",
            "==============================================================================================================\n",
            " input (InputLayer)                              [(None, 1392, 193)]                         0                \n",
            "                                                                                                              \n",
            " lambda_3 (Lambda)                               (None, 1392, 193, 1)                        0                \n",
            "                                                                                                              \n",
            " conv2d_6 (Conv2D)                               (None, 696, 97, 32)                         14432            \n",
            "                                                                                                              \n",
            " batch_normalization_6 (BatchNormalization)      (None, 696, 97, 32)                         128              \n",
            "                                                                                                              \n",
            " leaky_re_lu_9 (LeakyReLU)                       (None, 696, 97, 32)                         0                \n",
            "                                                                                                              \n",
            " conv2d_7 (Conv2D)                               (None, 696, 49, 32)                         236544           \n",
            "                                                                                                              \n",
            " batch_normalization_7 (BatchNormalization)      (None, 696, 49, 32)                         128              \n",
            "                                                                                                              \n",
            " leaky_re_lu_10 (LeakyReLU)                      (None, 696, 49, 32)                         0                \n",
            "                                                                                                              \n",
            " reshape_3 (Reshape)                             (None, 696, 1568)                           0                \n",
            "                                                                                                              \n",
            " bidirectional_15 (Bidirectional)                (None, 696, 256)                            1737728          \n",
            "                                                                                                              \n",
            " dropout_15 (Dropout)                            (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_16 (Bidirectional)                (None, 696, 256)                            394240           \n",
            "                                                                                                              \n",
            " dropout_16 (Dropout)                            (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_17 (Bidirectional)                (None, 696, 256)                            394240           \n",
            "                                                                                                              \n",
            " dropout_17 (Dropout)                            (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_18 (Bidirectional)                (None, 696, 256)                            394240           \n",
            "                                                                                                              \n",
            " dropout_18 (Dropout)                            (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " bidirectional_19 (Bidirectional)                (None, 696, 256)                            394240           \n",
            "                                                                                                              \n",
            " dense_6 (Dense)                                 (None, 696, 256)                            65792            \n",
            "                                                                                                              \n",
            " leaky_re_lu_11 (LeakyReLU)                      (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " dropout_19 (Dropout)                            (None, 696, 256)                            0                \n",
            "                                                                                                              \n",
            " dense_7 (Dense)                                 (None, 696, 31)                             7967             \n",
            "                                                                                                              \n",
            "==============================================================================================================\n",
            "Total params: 3,639,679\n",
            "Trainable params: 3,639,551\n",
            "Non-trainable params: 128\n",
            "______________________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "earlystopper = EarlyStopping(monitor=\"val_CER\", patience=20, verbose=1, mode=\"min\")\n",
        "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
        "trainLogger = TrainLogger(configs.model_path)\n",
        "tb_callback = TensorBoard(f\"{configs.model_path}/logs\", update_freq=1)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.8, min_delta=1e-10, patience=5, verbose=1, mode=\"auto\")\n",
        "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_data_provider,\n",
        "    validation_data=val_data_provider,\n",
        "    epochs=configs.train_epochs,\n",
        "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
        "    workers=configs.train_workers\n",
        ")\n",
        "\n",
        "# Save training and validation datasets as csv files\n",
        "train_data_provider.to_csv(os.path.join(configs.model_path, \"train.csv\"))\n",
        "val_data_provider.to_csv(os.path.join(configs.model_path, \"val.csv\"))"
      ],
      "metadata": {
        "id": "p4SVgM5Y59ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfde1f4-5ebc-47ec-d082-2d19cc4aebcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1474/1474 [==============================] - ETA: 0s - loss: 7.7570 - CER: 0.0246 - WER: 0.1207\n",
            "Epoch 1: val_CER improved from inf to 0.01837, saving model to /content/drive/MyDrive/CRNN-01/202306191330/model.h5\n",
            "1474/1474 [==============================] - 920s 597ms/step - loss: 7.7570 - CER: 0.0246 - WER: 0.1207 - val_loss: 6.2948 - val_CER: 0.0184 - val_WER: 0.0925 - lr: 5.0000e-04\n",
            "Epoch 2/3\n",
            "1474/1474 [==============================] - ETA: 0s - loss: 6.7310 - CER: 0.0217 - WER: 0.1082\n",
            "Epoch 2: val_CER did not improve from 0.01837\n",
            "1474/1474 [==============================] - 828s 561ms/step - loss: 6.7310 - CER: 0.0217 - WER: 0.1082 - val_loss: 8.0260 - val_CER: 0.0240 - val_WER: 0.1118 - lr: 5.0000e-04\n",
            "Epoch 3/3\n",
            "1474/1474 [==============================] - ETA: 0s - loss: 6.4139 - CER: 0.0207 - WER: 0.1048\n",
            "Epoch 3: val_CER did not improve from 0.01837\n",
            "1474/1474 [==============================] - 823s 558ms/step - loss: 6.4139 - CER: 0.0207 - WER: 0.1048 - val_loss: 6.9966 - val_CER: 0.0205 - val_WER: 0.0984 - lr: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "15aupEH_NanJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from mltu.preprocessors import WavReader\n",
        "from mltu.utils.text_utils import get_cer, get_wer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "    from mltu.configs import BaseModelConfigs\n",
        "\n",
        "    configs = BaseModelConfigs.load(\"/content/drive/MyDrive/CRNN-01/202306180741/configs.yaml\")\n",
        "\n",
        "    model = WavToTextModel(model_path=\"/content/drive/MyDrive/CRNN-01/202306180741/model.onnx\", char_list=configs.vocab, force_cpu=False)\n",
        "\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/CRNN-01/202306180741/val.csv\").values.tolist()\n",
        "\n",
        "    accum_cer, accum_wer = [], []\n",
        "    for wav_path, label in tqdm(df):\n",
        "\n",
        "        spectrogram = WavReader.get_spectrogram(wav_path, frame_length=configs.frame_length, frame_step=configs.frame_step, fft_length=configs.fft_length)\n",
        "        # WavReader.plot_raw_audio(wav_path, label)\n",
        "\n",
        "        padded_spectrogram = np.pad(spectrogram, ((configs.max_spectrogram_length - spectrogram.shape[0], 0),(0,0)), mode=\"constant\", constant_values=0)\n",
        "\n",
        "        # WavReader.plot_spectrogram(spectrogram, label)\n",
        "\n",
        "        text = model.predict(padded_spectrogram)\n",
        "\n",
        "        true_label = \"\".join([l for l in label.lower() if l in configs.vocab])\n",
        "\n",
        "        cer = get_cer(text, true_label)\n",
        "        wer = get_wer(text, true_label)\n",
        "\n",
        "        accum_cer.append(cer)\n",
        "        accum_wer.append(wer)\n",
        "\n",
        "        print(f\"Pred: {text}\")\n",
        "        print(f\"Actual: {true_label}\")\n",
        "\n",
        "        break\n",
        "\n",
        "    print(f\"Average CER: {np.average(accum_cer)}, Average WER: {np.average(accum_wer)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXqeUBsKRM-H",
        "outputId": "5a98f93e-e92e-491b-9756-44acbbe126ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1310 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: ned and set for ris ins first ansacin asi haboran ben anstrotet this fonte wol be fod spesil s l in main grambrt\n",
            "Actual: knead and set for risings first and second as you have already been instructed this sponge will be found especially useful in making graham bread\n",
            "Average CER: 0.3448275862068966, Average WER: 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}